{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the interactivity I'm using _plotly_ library and _Jupyter Widgets_. \n",
    "It allows to prototype dashboard in some way. Hence, for correct execution of the current notebook one has to install the following packages: \n",
    "   - [plotly](https://plot.ly/python/) + [cufflinks](https://plot.ly/ipython-notebooks/cufflinks/)\n",
    "   - [ipywidgets](https://github.com/jupyter-widgets/ipywidgets)\n",
    "\n",
    "and activate the required extensions for Jupyter. Feel free to do it manually or run the following script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# pip install plotly\n",
    "# pip install cufflinks\n",
    "# pip install ipywidgets\n",
    "# jupyter nbextension install --py --sys-prefix widgetsnbextension\n",
    "# jupyter nbextension install --py --sys-prefix plotlywidget\n",
    "# jupyter nbextension enable --py --sys-prefix widgetsnbextension\n",
    "# jupyter nbextension enable --py --sys-prefix plotlywidget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate the correct installation and activation of the required packages please execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known nbextensions:\n",
      "  config dir: /anaconda3/envs/DL/etc/jupyter/nbconfig\n",
      "    notebook section\n",
      "      plotlywidget/extension \u001b[32m enabled \u001b[0m\n",
      "      jupyter-js-widgets/extension \u001b[32m enabled \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      - Validating: \u001b[32mOK\u001b[0m\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "jupyter nbextension list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data I/O\n",
    "We assume that one has already obtained the embeddings for the researched financial statement network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings have been uploaded to memory!\n",
      "Final shape of DataFrame is  (58823, 9)\n",
      "Supported information has been uploaded to memory!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from NetEmbs import *\n",
    "\n",
    "MODE = \"SimulatedData\"\n",
    "\n",
    "\n",
    "if MODE == \"SimulatedData\":\n",
    "    EMBS_PATH = \"RefactoringExperiments_versionMetaDiff_directionCOMBI_walks30_pressure30_window3/TFsteps100000batch64_emb32/\"\n",
    "#     EMBS_PATH = \"Simulation_versionMetaDiff_directionCOMBI_walks30_pressure30_window3/TFsteps100000batch64_emb32/\"\n",
    "    embs = pd.read_pickle(EMBS_PATH+\"cache/Embeddings.pkl\")\n",
    "    print(\"Embeddings have been uploaded to memory!\")\n",
    "    d = upload_data(\"Simulation/FSN_Data.db\", limit=None)\n",
    "    d = prepare_data(d)\n",
    "    print(\"Supported information has been uploaded to memory!\")\n",
    "\n",
    "if MODE == \"RealData\":\n",
    "    import extras\n",
    "    import analysis\n",
    "    EMBS_PATH = \"model/15108_2017_versionMetaDiff_directionCOMBI_walks31_pressure30_window3/TFsteps100000batch64_emb32/\"\n",
    "    embs = pd.read_pickle(EMBS_PATH+\"cache/Embeddings.pkl\")\n",
    "        # //////// TODO UPLOAD your data HERE \\\\\\\\\\\\\\\\\\\\\n",
    "#     d = analysis.analysis(\"14082_2017\")\n",
    "    d = extras.getData(\"15108_2017\")\n",
    "        # //////// END  \\\\\\\\\\\\\\\\\\\\\n",
    "    # TODO pay attention for the split argument below!\n",
    "    if \"Value\" in list(d):\n",
    "        need_split = True\n",
    "    else:\n",
    "        need_split = False\n",
    "    d = prepare_dataMarcel(d, split=need_split)\n",
    "#     Here we drop the duplicate of GroundTruth in the DataFrame with supported info, because we have it in Embs DataFrame\n",
    "    if \"GroundTruth\" in list(d):\n",
    "        d.drop(\"GroundTruth\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Emb</th>\n",
       "      <th>GroundTruth</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>[-0.07386548, -0.030946685, -0.11357186, -0.04...</td>\n",
       "      <td>Sales 21 btw</td>\n",
       "      <td>1.543287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>[-0.23749885, -0.07744809, -0.17500901, -0.006...</td>\n",
       "      <td>Cost of Sales</td>\n",
       "      <td>1.543287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                                Emb    GroundTruth  \\\n",
       "0   8  [-0.07386548, -0.030946685, -0.11357186, -0.04...   Sales 21 btw   \n",
       "1   9  [-0.23749885, -0.07744809, -0.17500901, -0.006...  Cost of Sales   \n",
       "\n",
       "       Time  \n",
       "0  1.543287  \n",
       "1  1.543287  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Signature</th>\n",
       "      <th>FA_Name</th>\n",
       "      <th>Credit</th>\n",
       "      <th>Debit</th>\n",
       "      <th>Name</th>\n",
       "      <th>Value</th>\n",
       "      <th>from</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>([('Revenue', 0.82629), ('Tax', 0.17371)], [('...</td>\n",
       "      <td>NoisyRightFA_ilpe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>NoisyRightFA_ilpe_6</td>\n",
       "      <td>0.678201</td>\n",
       "      <td>False</td>\n",
       "      <td>0.678201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>([('Revenue', 0.82629), ('Tax', 0.17371)], [('...</td>\n",
       "      <td>NoisyRightFA_jhzg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>NoisyRightFA_jhzg_6</td>\n",
       "      <td>1.877578</td>\n",
       "      <td>False</td>\n",
       "      <td>1.877578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                          Signature            FA_Name  \\\n",
       "0   8  ([('Revenue', 0.82629), ('Tax', 0.17371)], [('...  NoisyRightFA_ilpe   \n",
       "1   8  ([('Revenue', 0.82629), ('Tax', 0.17371)], [('...  NoisyRightFA_jhzg   \n",
       "\n",
       "   Credit     Debit                 Name     Value   from    amount  \n",
       "0     0.0  0.001441  NoisyRightFA_ilpe_6  0.678201  False  0.678201  \n",
       "1     0.0  0.003988  NoisyRightFA_jhzg_6  1.877578  False  1.877578  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Interactive visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Decrease the dim of embeddings for visualization purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.manifold import TSNE\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "def dim_reduction(df, n_dim=2, rand_state=1):\n",
    "    if \"Emb\" in list(df):\n",
    "        tsne = TSNE(random_state=rand_state)\n",
    "        embdf = pd.DataFrame(list(map(np.ravel, df[\"Emb\"])))\n",
    "        embed_tsne = tsne.fit_transform(embdf)\n",
    "        df[\"x\"] = pd.Series(embed_tsne[:, 0])\n",
    "        df[\"y\"] = pd.Series(embed_tsne[:, 1])\n",
    "        return df\n",
    "    else:\n",
    "        raise KeyError(\"No Embs column in the given DataFrame!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "# Standard plotly imports\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, plot, init_notebook_mode\n",
    "# Using plotly + cufflinks in offline mode\n",
    "import cufflinks\n",
    "cufflinks.go_offline(connected=True)\n",
    "init_notebook_mode(connected=True)\n",
    "from ipywidgets import interactive, HBox, VBox, widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordClouds function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "# Count most frequent FA names in the given DataFrame OR FA names with the highest amount\n",
    "def findMostCommonFAs_v2(df, labels_column=\"label\", words_column=\"FA_Name\", amount_column=\"amount\", sort_mode=\"freq\", n_top=4, vis=False, folder=\"\"):\n",
    "    if labels_column not in list(df):\n",
    "        raise KeyError(f\"Given column name {labels_column} is not presented in the given DataFrame! Only allows: {list(df)}!\")\n",
    "    if \"from\" not in list(df):\n",
    "        raise KeyError(f\"Please ensure that column 'from' is presented in your DataFrame!\")\n",
    "    for name, group in df.groupby(labels_column):\n",
    "        print(\"Current cluster label is \", name)\n",
    "        gr = group.groupby([words_column, \"from\"])\n",
    "        counts = gr.size().to_frame(name='counts')\n",
    "        all_stat = counts.join(gr.agg({amount_column: sum, 'Debit': lambda x: list(x), 'Credit': lambda x: list(x)})\n",
    "              .rename(columns={amount_column: 'amount_sum', 'Debit': 'Debit_list', 'Credit': 'Credit_list'}))\\\n",
    "        .reset_index()\n",
    "        if sort_mode == \"freq\":\n",
    "            all_stat.sort_values(['counts', words_column], ascending=False, inplace=True)\n",
    "        elif sort_mode == \"amount\":\n",
    "            all_stat.sort_values(['amount_sum', word_column], ascending=False, inplace=True)\n",
    "#             Store all statistict for N_TOP values as dictionary for further visualization\n",
    "        text = {\"Left\": [(x[0], x[2], x[3], x[5]) for x in all_stat[all_stat[\"from\"]==True].values[:n_top]], \n",
    "                \"Right\": [(x[0], x[2], x[3], x[4]) for x in all_stat[all_stat[\"from\"]==False].values[:n_top]]}\n",
    "        if vis:\n",
    "            i = 0\n",
    "            fig, axes = plt.subplots(2,2)\n",
    "        for key, data in text.items():\n",
    "            if sort_mode == \"freq\":\n",
    "#             Take the most frequent FA names\n",
    "                to_vis = [(str(item[0]), item[1]) for item in data]\n",
    "            elif sort_mode == \"amount\":\n",
    "                to_vis = [(str(item[0]), item[2]) for item in data]\n",
    "            print(key, \"--->\", [item[:3] for item in data])\n",
    "            if vis:\n",
    "#                 WordClouds\n",
    "                axes[0, i].set_title(key, size=24)\n",
    "                wc = WordCloud(background_color=\"white\", width=800, height=400, max_font_size=84, min_font_size=14, repeat=False, relative_scaling=0.8, max_words=100)\n",
    "                if len(to_vis)>0:\n",
    "                    wc.generate_from_frequencies(dict(to_vis))\n",
    "                else:\n",
    "                    continue\n",
    "                axes[0, i].axis(\"off\")\n",
    "                axes[0, i].imshow(wc, interpolation=\"bilinear\")\n",
    "#                 Histograhm\n",
    "                [sns.distplot( item[3] , label=item[0], kde=False, bins=50, ax=axes[1, i], hist_kws={\"range\": (0, 1.0)}) for item in data if len(item[3])>4]\n",
    "                axes[1,i].legend(frameon=False, fontsize=14)\n",
    "                axes[1,i].set_xlim((0,1.0))\n",
    "                i+=1\n",
    "        if vis:\n",
    "            plt.tight_layout()\n",
    "#             plt.savefig(folder + \"img/WordClouds/\" + str(name), dpi=140, pad_inches=0.01)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Matplotlib colormap into plotly colorscale:\n",
    "import itertools\n",
    "def matplotlib_to_plotly(color_map=\"tab10\", pl_entries=10):\n",
    "    cmap = matplotlib.cm.get_cmap(color_map)\n",
    "    h = 1.0/(pl_entries-1)\n",
    "    pl_colorscale = []\n",
    "\n",
    "    for k in range(pl_entries):\n",
    "        C = list(map(np.uint8, np.array(cmap(k*h)[:3])*255))\n",
    "        pl_colorscale.append([k*h, 'rgb'+str((C[0], C[1], C[2]))])\n",
    "\n",
    "    return pl_colorscale\n",
    "\n",
    "def getColors_Markers(keys, cm=\"tab10\", n_color=10, markers = [\"circle\", \"diamond\", \"square\"]):\n",
    "    keys = sorted(keys)\n",
    "    color_map = dict(zip(keys, matplotlib_to_plotly(cm, n_color)*(len(keys)//n_color+1)))\n",
    "    marker_map = dict(zip(keys, list(itertools.chain(*[[m]*n_color for m in markers]))*(len(keys)//(3*n_color)+1)))\n",
    "    return color_map, marker_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs.GroundTruth.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row of Data: \n",
      " [-0.07386548 -0.03094669 -0.11357186 -0.04683372 -0.23738098 -0.19469109\n",
      "  0.1744771  -0.10974692  0.15939397 -0.27761593 -0.20839284  0.20180142\n",
      "  0.33275723 -0.13247178  0.09936162 -0.25082654 -0.13305676 -0.10631848\n",
      " -0.11174125  0.20219289  0.10907321 -0.17893675 -0.13183823  0.10541943\n",
      " -0.15657172  0.13912843  0.15979598 -0.27655786 -0.21184327  0.24745628\n",
      "  0.16048637 -0.14668946]\n"
     ]
    }
   ],
   "source": [
    "N_CLS = 11\n",
    "embs = dim_reduction(cl_Agglomerative(embs, N_CLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_measure(df):\n",
    "    str_labels = list(df.GroundTruth.unique())\n",
    "    real_labels = dict(zip(str_labels, range(len(str_labels))))\n",
    "    from sklearn.metrics import v_measure_score\n",
    "    v_measure_score(df.GroundTruth.apply(lambda x: real_labels[x]).values, df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Signature</th>\n",
       "      <th>FA_Name</th>\n",
       "      <th>Credit</th>\n",
       "      <th>Debit</th>\n",
       "      <th>Name</th>\n",
       "      <th>Value</th>\n",
       "      <th>from</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11</td>\n",
       "      <td>([('Cash', 1000.0)], [('EBPayables', 1000.0)])</td>\n",
       "      <td>Cash</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash4</td>\n",
       "      <td>-1000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11</td>\n",
       "      <td>([('Cash', 1000.0)], [('EBPayables', 1000.0)])</td>\n",
       "      <td>EBPayables</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>EBPayables_4</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                       Signature     FA_Name  Credit  \\\n",
       "21  11  ([('Cash', 1000.0)], [('EBPayables', 1000.0)])        Cash     1.0   \n",
       "22  11  ([('Cash', 1000.0)], [('EBPayables', 1000.0)])  EBPayables     0.0   \n",
       "\n",
       "    Debit          Name   Value   from  amount  \n",
       "21    0.0         Cash4 -1000.0   True  1000.0  \n",
       "22    1.0  EBPayables_4  1000.0  False  1000.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[d[\"ID\"]==11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e05a3372527419992b1bfbe706c94e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=''), FigureWidget({\n",
       "    'data': [{'customdata': [2, 3, 5, ..., 10151, 10155, 10161]â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO before visualization one has to use t-SNE!\n",
    "# Label text\n",
    "description = widgets.Label(\n",
    "        value=''\n",
    "    )\n",
    "# WordCouds area\n",
    "wordCloudsOutput = widgets.Output()\n",
    "# Table with JournalEntries data\n",
    "table_titles = [\"ID\", \"FA_Name\", \"Credit\", \"Debit\", \"label\"]\n",
    "\n",
    "if MODE == \"RealData\":\n",
    "    table_titles = [\"ID\", \"FA_Name\", \"accountDesc\", \"Credit\", \"Debit\", \"label\"]\n",
    "    \n",
    "t = go.FigureWidget([go.Table(\n",
    "    header=dict(values=table_titles,\n",
    "                fill = dict(color='#C2D4FF'),\n",
    "                align = ['left'] * 5),\n",
    "    cells=dict(values=[],\n",
    "               fill = dict(color='#F5F8FF'),\n",
    "               align = ['left'] * 5))],\n",
    "                    layout = go.Layout(\n",
    "                            title=\"Journal Entries\",\n",
    "                            autosize=True,\n",
    "                            width=1000,\n",
    "                            height=400))\n",
    "# Scatter plot\n",
    "N_COLORS = 10\n",
    "# WORD_CLOUD_LABEL = \"FA_Name\"\n",
    "LEGEND_TITLE = \"GroundTruth\"\n",
    "LEGEND_TITLE = \"label\"\n",
    "tmp_p_see = None\n",
    "# For selection via multiple traces... stupid way.\n",
    "indexes = []\n",
    "tr_nums = 0\n",
    "\n",
    "\n",
    "def interactiveScatter(df, df_info, legend_title=\"label\"):\n",
    "    \"\"\"Create FigureWidget with the scatter plot for the given DataFrame\"\"\"\n",
    "    scatter_data = list()\n",
    "    cmap, mmap = getColors_Markers(keys=df[legend_title].unique(), n_color=N_COLORS)\n",
    "    for name, group in df.groupby(legend_title):\n",
    "        scatter_data.append(go.Scatter(x=group.x, y=group.y, mode='markers', name=name, \n",
    "                                    text = group.apply(lambda row: f\"ID={row.ID},   GroundTruth={row.GroundTruth}\", axis=1),\n",
    "                                    customdata = group.index.to_list(),\n",
    "                                    marker=dict(color=cmap[name][1], \n",
    "                                                symbol=mmap[name])))\n",
    "    f = go.FigureWidget(data=scatter_data,\n",
    "                       layout = go.Layout(\n",
    "                           title=f\"t-SNE visualisation with coloring based on {legend_title}\",\n",
    "        hovermode='closest',\n",
    "        autosize=True,\n",
    "        width=1000,\n",
    "        height=700))\n",
    "    \n",
    "    def printSignature(trace, points, *args):\n",
    "        if len(points.point_inds)>0:\n",
    "            ids = trace.customdata[points.point_inds[0]]\n",
    "            row = df.iloc[ids]\n",
    "            description.value = f\"ID={row.ID},   GroundTruth={row.GroundTruth}\"\n",
    "    def selectBP(trace, points, *args):\n",
    "        if len(points.point_inds)>0:\n",
    "            ids = trace.customdata[points.point_inds[0]]\n",
    "            row = df.iloc[[ids]]\n",
    "            chosen_bps = df_info.merge(row, on=\"ID\")\n",
    "            t.data[0].cells.values = [chosen_bps[col] for col in t.data[0].header.values]\n",
    "    \n",
    "    def filterRows(selected_ids):\n",
    "        row = df.iloc[selected_ids]\n",
    "        chosen_bps = df_info.merge(row, on=\"ID\")\n",
    "        return chosen_bps\n",
    "    def updateTable(chosen_bps):\n",
    "        t.data[0].cells.values = [chosen_bps[col] for col in t.data[0].header.values]\n",
    "    def showClouds(chosen_bps):\n",
    "        wordCloudsOutput.clear_output()\n",
    "        with wordCloudsOutput:\n",
    "            findMostCommonFAs_v2(chosen_bps, LEGEND_TITLE, WORD_CLOUD_LABEL, sort_mode=\"freq\", vis=True, n_top=4)\n",
    "    scatters = f.data\n",
    "    max_traces = len(scatters)\n",
    "    def selectBPs(trace,points,selector):\n",
    "        global indexes\n",
    "        global tr_nums\n",
    "#         print(f\"For trace index={points.trace_index} tr_nums is {tr_nums}\")\n",
    "        if not points.point_inds:\n",
    "            pass\n",
    "        else:\n",
    "            indexes.extend([trace.customdata[cur_point] for cur_point in points.point_inds])\n",
    "        tr_nums = tr_nums+1\n",
    "        if tr_nums==max_traces:\n",
    "            selected_data = filterRows(indexes)\n",
    "            updateTable(selected_data)\n",
    "            showClouds(selected_data)\n",
    "            indexes = []\n",
    "            tr_nums = 0\n",
    "    # Hover text: ID and GroundTruth\n",
    "    for scatter in scatters:\n",
    "        scatter.hoverinfo = 'text'\n",
    "        scatter.on_hover(printSignature) \n",
    "        scatter.on_click(selectBP)\n",
    "        scatter.on_selection(selectBPs)\n",
    "\n",
    "    # Selection\n",
    "    return f\n",
    "# @interact(Coloring=['label', 'GroundTruth'])\n",
    "# def update(Coloring=\"label\"):\n",
    "#     print(Coloring)\n",
    "#     f_scatter = interactiveScatter(embs, Coloring)\n",
    "#     return VBox([description, f_scatter])\n",
    "f_scatter = interactiveScatter(embs, d, LEGEND_TITLE)\n",
    "VBox([description, f_scatter, t, wordCloudsOutput])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# sklearn.metrics.pairwise.cosine_similarity(embs[embs.ID==10].Emb.values[0].reshape(1,-1), \n",
    "#                                            embs[embs.ID==970].Emb.values[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Series modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosscorr(data_x, data_y, lag=0):\n",
    "    \"\"\" Lag-N cross correlation. \n",
    "    Parameters\n",
    "    ----------\n",
    "    lag : int, default 0\n",
    "    datax, datay : pandas.Series objects of equal length\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    crosscorr : float\n",
    "    \"\"\"\n",
    "    return data_x.shift(lag).corr(data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initial hypotheis is that sub-groups of business process within a company should have some kind of cross correlation (e.g. goods delivery business process follows after sale business process). For deeper investigation of that hypothesis we are going to aggregate given Journal Entries (aka input raw data) based on the predicted cluster label and to build time-series from these groups w.r.t. to the transaction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO helper uploader for obtain Time column. \n",
    "if MODE==\"SimulatedData\":\n",
    "    df_all = d.merge(upload_JournalEntriesTruth(\"Simulation/FSN_Data.db\", limit=None)[[\"ID\", \"Time\"]], on=\"ID\")\\\n",
    "        .drop([\"Signature\", \"Name\"], axis=1)\n",
    "    print(f\"Shape of supported info is {df_all.shape}, shape of embs DataFrame is {embs.shape}\")\n",
    "    df_all = df_all.merge(embs, on=\"ID\")\n",
    "    print(f\"After merge the shape is {df_all.shape}\")\n",
    "    df_all = df_all.groupby([\"ID\", \"FA_Name\", \"from\"], as_index=False).aggregate({\"amount\": lambda x: np.sum(x), \n",
    "                                \"Time\": \"first\",\n",
    "                              \"GroundTruth\": \"first\",\n",
    "                              \"label\": \"first\",\n",
    "                              \"x\": \"first\",\n",
    "                              \"y\": \"first\"}) \\\n",
    "                        .sort_values(\"Time\", ascending=True)\n",
    "if MODE==\"RealData\":\n",
    "    d[\"Date\"] = pd.to_datetime(d[\"Date\"],format='%Y-%m-%d')\n",
    "#     df_all = d.groupby(\"ID\", as_index=False).aggregate({\"amount\": lambda x: np.sum(x)/2.0, \n",
    "#                                \"Date\": \"first\"}).merge(embs, on=\"ID\").sort_values(\"Date\", ascending=True)\n",
    "    df_all = d.groupby([\"ID\", \"FA_Name\", \"from\"], as_index=False)\\\n",
    "                .aggregate({\"amount\": lambda x: np.sum(x), \n",
    "                            \"Date\": \"first\",\n",
    "                           \"accountDesc\": \"first\"})\\\n",
    "                .merge(embs, on=\"ID\")\\\n",
    "                .sort_values(\"Date\", ascending=True)\n",
    "    df_all.set_index(df_all.Date, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add DateTimeIndex to simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDateTimeIndex(df):\n",
    "    df[\"SimulatedTime\"] = df[\"Time\"]\n",
    "    df[\"Time\"] = df[\"Time\"].apply(lambda x: np.datetime64('2019-01-01')+np.timedelta64(int(x*28.8), 'm'))\n",
    "    return df.set_index(\"Time\")\n",
    "if MODE==\"SimulatedData\":\n",
    "    df_all = addDateTimeIndex(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find optimal scaling for simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def findDateTimeIndex(dfA, dfB, mult=55, on=\"Time\", data_column=\"amount\", agg_period=\"D\"):\n",
    "#     dfA = dfA.set_index(dfA[on].apply(lambda x: np.datetime64('2019-01-01')+np.timedelta64(int(x*mult), 'm')))\n",
    "#     dfB = dfB.set_index(dfB[on].apply(lambda x: np.datetime64('2019-01-01')+np.timedelta64(int(x*mult), 'm')))\n",
    "# #     return dfA, dfB\n",
    "#     return crosscorr(dfA[data_column].resample(agg_period).sum(), dfB[data_column].resample(agg_period).sum(), 0)\n",
    "\n",
    "# res = {cur_m: findDateTimeIndex(sales, collections, agg_period=\"D\", mult=cur_m) for cur_m in np.linspace(50, 150, 200)}\n",
    "# res = sorted(res.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get part of data with required labe/GroundTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterData(df, query=[[\"Sales 21 btw\", \"Sales 6 btw\"], [\"Collections\"]], on=\"GroundTruth\"):\n",
    "    result = list()\n",
    "    for q in query:\n",
    "        result.append(df_all[df_all[on].isin(q)])\n",
    "        result[-1].name=str(q)[1:-1]\n",
    "        if on == \"label\":\n",
    "            result[-1].name+=\" cluster\"\n",
    "    return tuple(result)\n",
    "\n",
    "def filterData_v3(df, \n",
    "                  query=[{\"select\": [\"Sales 21 btw\", \"Sales 6 btw\"], \n",
    "                              \"_with\": {\"FA_Name\": \"Revenue\", \"from\": True}}, \n",
    "                 {\"select\": [\"Collections\"], \"_with\": None}], \n",
    "                  on=\"GroundTruth\"):\n",
    "    result = list()\n",
    "    for q in query:\n",
    "        postfix = \"\"\n",
    "        if q[\"select\"] is None:\n",
    "            cur_df = df\n",
    "        else:\n",
    "            cur_df = df[df[on].isin(q[\"select\"])]\n",
    "        if q[\"_with\"] is not None:\n",
    "            for key, value in q[\"_with\"].items():\n",
    "                try:\n",
    "                    cur_df = cur_df[cur_df[key]==value]\n",
    "                    postfix+=\"_\"+str(value)\n",
    "                except KeyError as e:\n",
    "                    raise(f\"{a} is not in a columns titles!\")\n",
    "        result.append(cur_df)\n",
    "        result[-1].name=str(q[\"select\"])+postfix\n",
    "        if on == \"label\":\n",
    "            result[-1].name+=\" cluster\"\n",
    "    if len(result)==1:\n",
    "        return result[0]\n",
    "    else:\n",
    "        return tuple(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "def plotAmounts(DFs, title=\"Default signals\", vis_type=\"line\"):\n",
    "    \"\"\"Helper funciton to plot a few DataFrame in one plotly graph\"\"\"\n",
    "    if vis_type==\"line\":\n",
    "        if len(DFs)>1:\n",
    "            fig2 = go.Figure(data=[go.Scatter(x=df.index,\n",
    "            y=df.amount,\n",
    "            name=df.name\n",
    "            ) for df in DFs], \n",
    "            layout = go.Layout(showlegend=True, title=go.layout.Title(text=title), hovermode='closest'))\n",
    "        else:\n",
    "            fig2 = go.Figure(data=go.Scatter(x=DFs.index,\n",
    "            y=DFs.amount,\n",
    "            name=DFs.name, \n",
    "            layout = go.Layout(showlegend=True, title=go.layout.Title(text=title), hovermode='closest')))\n",
    "        iplot(fig2)\n",
    "    elif vis_type == \"scatter\" and len(DFs)==2:\n",
    "        print([df.shape for df in DFs])\n",
    "        import seaborn as sns\n",
    "        if MODE==\"SimulatedData\":\n",
    "            sc_data = DFs[0].merge(DFs[1], on=\"Time\", how=\"inner\", suffixes=(\"_X\", \"_Y\"))\n",
    "        elif MODE==\"RealData\":\n",
    "            sc_data = DFs[0].merge(DFs[1], on=\"Date\", how=\"inner\", suffixes=(\"_X\", \"_Y\"))\n",
    "        sns.regplot(x=sc_data.amount_X, y=sc_data.amount_Y)\n",
    "#         regr = linear_model.LinearRegression()\n",
    "#         regr.fit(DFs[0].amount.values.reshape(-1, 1), DFs[1].amount.values.reshape(-1, 1))\n",
    "#         fig2 = go.Figure(data=[go.Scatter(x=DFs[0].amount, y=DFs[1].amount, mode='markers', name=\"Amounts\"),\n",
    "#                               go.Scatter(x=DFs[0].amount, y=regr.predict(DFs[0].amount.values.reshape(-1, 1)), name = \"Best fit\",\n",
    "#                 mode='lines',\n",
    "#                 line=dict(color='blue', width=2)\n",
    "#                 )],\n",
    "#                 layout = go.Layout(showlegend=True, \n",
    "#                                             title=go.layout.Title(text=str(DFs[0].name) +\" vs. \" + str(DFs[1].name))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = filterData_v3(df_all, query=[{\"select\": [\"Sales 21 btw\", \"Sales 6 btw\"], \n",
    "                              \"_with\": None}, \n",
    "                                {\"select\": [\"Collections\"], \"_with\": None}], on=\"GroundTruth\")\n",
    "plotAmounts(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample our TimeSeries with Dayly/Weekly/Monthly frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = df_filtered[0]\n",
    "collections = df_filtered[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_w = sales.resample(\"D\").apply({\"amount\": sum, \"GroundTruth\": pd.Series.mode, \"label\": pd.Series.mode})\n",
    "sales_w.name = sales.name+\", weekly\"\n",
    "collections_w = collections.resample(\"D\").apply({\"amount\": sum, \"GroundTruth\": pd.Series.mode, \"label\": pd.Series.mode})\n",
    "collections_w.name = collections.name+\", weekly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAmounts([sales_w, collections_w], vis_type=\"line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All in One function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "legend_postfix = {\"W\": \", weekly\", \"D\": \", daily\", \"M\": \", monthly\"}\n",
    "def constructSignals(df_all, query=[{\"select\": [2], \"_with\": None}, {\"select\": [4], \"_with\": None}], \n",
    "                     on=\"label\", agg_period=\"W\", vis_type=\"line\"):\n",
    "    # Predicted labels\n",
    "    agg_title = \"Aggregated signals\"\n",
    "    sales, collections = filterData_v3(df_all, query=query, on=on)\n",
    "#     plotAmounts([sales, collections], \"Original signals, without aggregation\")\n",
    "    print(\"Started aggregation...\")\n",
    "    sales_w = sales.resample(agg_period).agg({\"amount\": sum})\n",
    "    collections_w = collections.resample(agg_period).apply({\"amount\": sum})\n",
    "#     Add info about aggregation period to legen texts\n",
    "    try:\n",
    "        sales_w.name = sales.name+legend_postfix[agg_period]\n",
    "        collections_w.name = collections.name+legend_postfix[agg_period]\n",
    "        agg_title+=legend_postfix[agg_period]\n",
    "    except KeyError as e:\n",
    "        print(f\"Could not intepret {agg_period} for adding postfix to legend text... Use the default ones..\" )\n",
    "        sales_w.name = sales.name\n",
    "        collections_w.name = collections.name\n",
    "    plotAmounts([sales_w, collections_w], agg_title, vis_type=vis_type)\n",
    "    print([crosscorr(sales.amount.resample(agg_period).sum(), collections.amount.resample(agg_period).sum(), lag) for lag in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "constructSignals(df_all, query=[{\"select\": [\"Sales 6 btw\", \"Sales 21 btw\"], \n",
    "                              \"_with\": None}, \n",
    "                                {\"select\": [\"Collections\"], \"_with\": None}], on=\"GroundTruth\", agg_period=\"D\", vis_type=\"line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tax vs. Revenue based on the Sales , GroundTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "constructSignals(df_all, query=[{\"select\": [\"Sales 21 btw\"], \n",
    "                              \"_with\": {\"FA_Name\": \"Revenue\"}}, \n",
    "                                {\"select\": [\"Sales 21 btw\"], \"_with\": {\"FA_Name\": \"Tax\"}}], on=\"GroundTruth\", agg_period=\"D\", vis_type=\"line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tax vs. Revenue based on the Sales *as-expert*-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_is_sale(df):\n",
    "    return pd.Series({\"ID\": df.ID.values[0], \"is_Sale\": (\"Revenue\" in df[df[\"from\"]==True].FA_Name.unique()) and (\"TradeReceivables\" in df[df[\"from\"]==False].FA_Name.unique())})\n",
    "expert_sales = df_all.reset_index()\\\n",
    "        .merge(df_all.groupby(\"ID\", as_index=False).apply(check_is_sale), on=\"ID\", left_index=True)\\\n",
    "        .set_index(\"Time\", drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "constructSignals(expert_sales, query=[{\"select\": [True], \n",
    "                              \"_with\": {\"FA_Name\": \"Revenue\"}}, \n",
    "                                {\"select\": [True], \"_with\": {\"FA_Name\": \"Tax\"}}], on=\"is_Sale\", agg_period=\"D\", vis_type=\"line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tax vs. Revenue based on the Sales predicted-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "constructSignals(df_all, query=[{\"select\": [1, 2], \n",
    "                              \"_with\": {\"FA_Name\": \"Revenue\"}}, \n",
    "                                {\"select\": [1, 2], \"_with\": {\"FA_Name\": \"Tax\"}}], on=\"label\", agg_period=\"D\", vis_type=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import iplot\n",
    "import plotly.figure_factory as ff\n",
    "import seaborn as sns\n",
    "def calculate_corr(df_all, query=[1, 2], on=\"label\", agg_period=\"2D\", lag=0):\n",
    "    X, Y = [df_all[df_all[on]==q] for q in query]\n",
    "    return crosscorr(X.amount.resample(agg_period).sum(), Y.amount.resample(agg_period).sum(), lag)\n",
    "\n",
    "def get_corr_matrix(df, on=\"label\", agg_period=\"D\", lag=0):\n",
    "    labels = sorted(df[on].unique())\n",
    "    corr_matrix = np.zeros((len(labels), len(labels)))\n",
    "    for x_pos, x in enumerate(labels):\n",
    "        for y_pos, y in enumerate(labels):\n",
    "            if x!=y:\n",
    "                try:\n",
    "                    corr_matrix[x_pos, y_pos] = calculate_corr(df, query=[x,y], on=on, agg_period=agg_period, lag=lag)\n",
    "                except FloatingPointError as float_er:\n",
    "                    corr_matrix[x_pos, y_pos] = 0.0\n",
    "    return corr_matrix\n",
    "\n",
    "axis_prefix = {\"label\": \"Cluster \", \"GroundTruth\": \"\"}\n",
    "\n",
    "\n",
    "def make_annotations(z, x, y, annotation_text):\n",
    "    annotations = []\n",
    "    for n, row in enumerate(z):\n",
    "        for m, val in enumerate(row):\n",
    "            annotations.append(\n",
    "                go.layout.Annotation(\n",
    "                    text=str(annotation_text[n][m]) if annotation_text[n][m] != 0.0 else \"\",\n",
    "                    x=x[m],\n",
    "                    y=y[n],\n",
    "                    xref='x1',\n",
    "                    yref='y1',\n",
    "                    font=dict(color=\"Black\"),\n",
    "                    showarrow=False))\n",
    "    return annotations\n",
    "\n",
    "\n",
    "def corrHeatmap_interactive(corr_matrix, labels, on=\"label\"):\n",
    "    x = [axis_prefix[on] + str(cl) for cl in labels]\n",
    "    y = [axis_prefix[on] + str(cl) for cl in labels]\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.ones_like(corr_matrix, dtype=np.bool)\n",
    "    mask[np.tril_indices_from(mask, k=0)] = False\n",
    "    corr_matrix[mask] = 0.0\n",
    "    z_text = np.round(corr_matrix, 2)\n",
    "    cs = [[00.0, 'rgb(31, 119, 180)'],  # blue\n",
    "          [0.5, 'rgb(255,255,255)'],  # white\n",
    "          [1, 'rgb(214, 39, 40)']]  # red\n",
    "\n",
    "    trace = go.Heatmap(z=corr_matrix, x=x, y=y, zmid=0, zmin=-1, zmax=1, colorscale=cs, showscale=True,\n",
    "                       colorbar={\"thickness\": 20, \"len\": 0.5, \"outlinewidth\": 0, \"xpad\": 25,\n",
    "                                 \"title\": {\"text\": \"\\n \\n Correlation\", \"side\": \"right\"}})\n",
    "    fig = go.Figure(data=[trace])\n",
    "    fig.layout.title = go.layout.Title(text=\"Cross-correlation for the \" + on)\n",
    "    fig.layout.height = len(labels) * 70 + 200\n",
    "    fig.layout.width = len(labels) * 70 + 25 + 25 + 150\n",
    "    fig.layout.margin = go.layout.Margin(l=100, r=50, b=100, t=200, pad=10)\n",
    "    fig.layout.annotations = make_annotations(corr_matrix, x, y, z_text)\n",
    "    fig.layout.xaxis.side = \"top\"\n",
    "    fig.layout.yaxis.automargin = True\n",
    "    fig.layout.xaxis.automargin = True\n",
    "    iplot(fig)\n",
    "\n",
    "\n",
    "def corrHeatmap_static(corr_matrix, labels, on=\"label\"):\n",
    "    sns.set_context(\"paper\", rc={'figure.figsize': (20, 10), \"font.size\": 12, \"axes.titlesize\": 16, \"axes.labelsize\": 20,\n",
    "                        \"xtick.labelsize\": 12, \"ytick.labelsize\": 12})\n",
    "    x_ticks = [axis_prefix[on] + str(cl) for cl in labels]\n",
    "    y_ticks = [axis_prefix[on] + str(cl) for cl in labels]\n",
    "    z_text = np.round(corr_matrix, 2)\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.zeros_like(corr_matrix, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "    sns.heatmap(corr_matrix, mask=mask, annot=z_text, cmap=\"RdBu_r\", vmin=-1, vmax=1, center=0, xticklabels=x_ticks,\n",
    "                yticklabels=y_ticks,\n",
    "                square=True, linewidths=.1, cbar_kws={\"shrink\": .5})\n",
    "    ax.set_title(\"Cross-correlation for the \" + on)\n",
    "    plt.tight_layout()\n",
    "    plt.plot()\n",
    "    \n",
    "def correlationMatrix(df, on=\"label\", agg_period=\"D\", lag=0, interactive=True):\n",
    "    corr_matrix = get_corr_matrix(df, on=on, agg_period=agg_period, lag=lag)\n",
    "    labels = sorted(df[on].unique())\n",
    "    if interactive:\n",
    "#         Use plotly\n",
    "        return corrHeatmap_interactive(corr_matrix, labels=labels, on=on)\n",
    "    else:\n",
    "#         Use seaborn for visualization\n",
    "        corrHeatmap_static(corr_matrix, labels=labels, on=on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationMatrix(df_all, on=\"label\", agg_period=\"2D\", interactive=True)\n",
    "correlationMatrix(df_all, on=\"GroundTruth\", agg_period=\"2D\", interactive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters 0 and 2 in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_0 = df_all[df_all[\"label\"] == 0]\n",
    "cl_0_D = cl_0.amount.resample(\"D\").sum()\n",
    "cl_2 = df_all[df_all[\"label\"] == 1]\n",
    "cl_2_D = cl_2.amount.resample(\"D\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.pearsonr(cl_0_D, cl_2_D), stats.spearmanr(cl_0_D, cl_2_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_0.resample(\"D\").agg({\"amount\": sum}).rename(columns={\"amount\": \"Cluster 0\"}).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DL]",
   "language": "python",
   "name": "conda-env-DL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
